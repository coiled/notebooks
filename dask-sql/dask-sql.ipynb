{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing data with Dask, SQL, and Coiled\n",
    "\n",
    "In this notebook, we look at using [Dask-SQL](https://dask-sql.readthedocs.io/en/latest/), an exciting new open-source library which adds a SQL query layer on top of Dask. This allows you to query and transform Dask DataFrames using common SQL operations.\n",
    "\n",
    "## Launch a cluster\n",
    "\n",
    "Let's first start by creating a Coiled cluster which uses the `examples/dask-sql` software environment, which has `dask`, `pandas`, `s3fs`, and a few other libraries installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "\n",
    "cluster = coiled.Cluster(\n",
    "    n_workers=10,\n",
    "    worker_memory=\"30GiB\",\n",
    "    software=\"examples/dask-sql\",\n",
    ")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then connect Dask to our remote Coiled cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(cluster)\n",
    "client.wait_for_workers(10)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Dask-SQL\n",
    "\n",
    "Internally, Dask-SQL uses a well-established Java library, Apache Calcite, to parse SQL and perform some initial work on your query. To help Dask-SQL locate JVM shared libraries, we set the `JAVA_HOME` environment variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = os.environ[\"CONDA_DIR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main interface for interacting with Dask-SQL is the `dask_sql.Context` object. It allows your to register Dask DataFrames as data sources and can convert SQL queries to Dask DataFrame operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_sql import Context\n",
    "\n",
    "c = Context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this notebook, we'll use the NYC taxi dataset, which is publically accessible on AWS S3, as our data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from distributed import wait\n",
    "\n",
    "df = dd.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv\",\n",
    "    dtype={\n",
    "        \"payment_type\": \"UInt8\",\n",
    "        \"VendorID\": \"UInt8\",\n",
    "        \"passenger_count\": \"UInt8\",\n",
    "        \"RatecodeID\": \"UInt8\",\n",
    "    },\n",
    "    storage_options={\"anon\": True}\n",
    ")\n",
    "\n",
    "# Load datasest into the cluster's distributed memory.\n",
    "# This isn't strictly necessary, but does allow us to\n",
    "# avoid repeated running the same I/O operations. \n",
    "df = df.persist()\n",
    "wait(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use our `dask_sql.Context` to assign a table name to this DataFrame, and then use that table name within SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registers our Dask DataFrame df as a table with the name \"taxi\"\n",
    "c.register_dask_table(df, \"taxi\")\n",
    "\n",
    "# Perform a SQL operation on the \"taxi\" table\n",
    "result = c.sql(\"SELECT count(1) FROM taxi\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this returned another Dask DataFrame and no computation has been run yet. This is similar to other Dask DataFrame operations, which are lazily evaluated. We can call `.compute()` to run the computation on our cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray, we've run our first SQL query with Dask-SQL! Let's try out some more complex queries.\n",
    "\n",
    "## More complex SQL examples\n",
    "\n",
    "With Dask-SQL we can run more complex SQL statements like, for example, a groupby-aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.sql('SELECT avg(tip_amount) FROM taxi GROUP BY passenger_count').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: that the equivalent operatation using the Dask DataFrame API would be:\n",
    "\n",
    "```python\n",
    "df.groupby(\"passenger_count\").tip_amount.mean().compute()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even make plots of our SQL query results for near-real-time interactive data exploration and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.sql(\"\"\"\n",
    "    SELECT floor(trip_distance) AS dist, avg(fare_amount) as fare\n",
    "    FROM taxi \n",
    "    WHERE trip_distance < 50 AND trip_distance >= 0 \n",
    "    GROUP BY floor(trip_distance)\n",
    "\"\"\").compute().plot(x=\"dist\", y=\"fare\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to learn more about Dask-SQL check out the [Dask-SQL docs](https://dask-sql.readthedocs.io/) or [source code](https://github.com/nils-braun/dask-sql) on GitHub."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
